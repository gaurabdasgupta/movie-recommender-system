{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import svd\n",
    "import math\n",
    "from numpy import linalg as LA\n",
    "import scipy\n",
    "from scipy.sparse import load_npz\n",
    "from collections import Counter\n",
    "import math\n",
    "import time ## To measure processor time, not real time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Looks like this\n",
      "   userId  movieId  rating\n",
      "0     196      242       3\n",
      "1     186      302       3\n",
      "2      22      377       1\n",
      "3     244       51       2\n",
      "4     166      346       1\n",
      "\n",
      "Number of ratings present : 100000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#print(\"**Dataset Originally looks like this**\\n\")\n",
    "#ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "#print(ratings.head())\n",
    "ratings = pd.read_table('./datasets/ml-100k/u.data', sep='\\t', header=None, names=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "ratings.drop(labels='timestamp',axis=1,inplace=True)\n",
    "#print(\"\\n\\n**\\tAfter Dropping  **\")\n",
    "print(\"Dataset Looks like this\")\n",
    "print(ratings.head())\n",
    "\n",
    "print(\"\\nNumber of ratings present : \" + str(len(ratings.values)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting df to equivalent Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeUtilityMatrix(ratings, verbose = True):\n",
    "    intermediateMoviesMatrix = np.array(ratings.values)\n",
    "    usersList = intermediateMoviesMatrix[:,0].astype(int)\n",
    "    moviesList = intermediateMoviesMatrix[:,1].astype(int)\n",
    "    if verbose:\n",
    "        print(\"Min User ID : \"   + str(usersList.min()) + \\\n",
    "              \"\\nMax User ID : \" + str(usersList.max()) + \\\n",
    "              \"\\nUnique User IDs : \" + str(len(np.unique(usersList))) \\\n",
    "             )\n",
    "\n",
    "        print(\"\")\n",
    "\n",
    "        print(\"Min Movie ID : \"   + str(moviesList.min()) + \\\n",
    "              \"\\nMax Movie ID : \" + str(moviesList.max()) + \\\n",
    "              \"\\nUnique Movie IDs : \" + str(len(np.unique(moviesList))) \\\n",
    "             )\n",
    "\n",
    "    movieAliasNext = 0\n",
    "    movieAlises = dict()\n",
    "    for i in moviesList:\n",
    "        if i not in movieAlises:\n",
    "            movieAlises[i] = movieAliasNext\n",
    "            movieAliasNext += 1\n",
    "    \n",
    "    ## Creating a utility matrix\n",
    "    ratingsMatrix = np.zeros(shape=(len(np.unique(usersList)), len(np.unique(moviesList))))\n",
    "    for row in ratings.values:\n",
    "        ## print(row)\n",
    "        userID = int(row[0])\n",
    "        movieID = int(row[1])\n",
    "        rating  = row[2]\n",
    "        ratingsMatrix[userID-1][movieAlises[movieID]] = rating\n",
    "    print(ratingsMatrix)\n",
    "    return ratingsMatrix,movieAlises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min User ID : 1\n",
      "Max User ID : 943\n",
      "Unique User IDs : 943\n",
      "\n",
      "Min Movie ID : 1\n",
      "Max Movie ID : 1682\n",
      "Unique Movie IDs : 1682\n",
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " [0. 2. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ratingsMatrix,_ = makeUtilityMatrix(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5. 0. 0. ... 0. 0. 0.]\n",
      " [5. 5. 0. ... 0. 0. 0.]\n",
      " [0. 2. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Number of items for validation : 40094\n"
     ]
    }
   ],
   "source": [
    "def validationData(df, split = 0.8):\n",
    "    ratingsMatrix,alias = makeUtilityMatrix(df,False)\n",
    "    \n",
    "    mask = np.random.rand(len(df)) < split\n",
    "    test = df[~mask]\n",
    "    testUserMoviePairList = []\n",
    "    for t in test.values:\n",
    "        testUserMoviePairList.append( (int(t[0]-1),alias[int(t[1])]))\n",
    "        #ratingsMatrix[t[0]][t[1]] = 0\n",
    "    return (ratingsMatrix, testUserMoviePairList)\n",
    "\n",
    "testRatingMatrix, testPairList = validationData(ratings,split=0.60)\n",
    "print(\"Number of items for validation : \" + str(len(testPairList)))\n",
    "## print(testPairList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Similarity Matrix\n",
    "Both user user and item item is supported by this function. Optimised to run fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSimilarityMatrix(utilityMatrix,similarityBetween=\"user-user\", center=True):\n",
    "    \"\"\"\n",
    "    We are generating user user similarity using the Pearson Correlation Coefficient. if center = True\n",
    "    This ensures that the generous raters and strict raters are handled appropriately.\n",
    "    \"\"\"\n",
    "    assert type(utilityMatrix) == np.ndarray\n",
    "    assert similarityBetween == \"user-user\" or similarityBetween == 'item-item'\n",
    "    \n",
    "    utilityMatrix = np.copy(utilityMatrix)\n",
    "    \n",
    "    if similarityBetween == 'item-item':\n",
    "        utilityMatrix = np.transpose(utilityMatrix)\n",
    "    \n",
    "    numUsers = utilityMatrix.shape[0]\n",
    "    numItems = utilityMatrix.shape[1]\n",
    "    if center:\n",
    "        for i in range(numUsers):\n",
    "            nonZero = 0\n",
    "            rollingSum = 0\n",
    "            for j in range(numItems):\n",
    "                if utilityMatrix[i][j] != 0:\n",
    "                    nonZero += 1\n",
    "                    rollingSum += utilityMatrix[i][j]\n",
    "\n",
    "            if(nonZero > 0):\n",
    "                centreVal = rollingSum / nonZero\n",
    "            else:\n",
    "                centreVal = 0\n",
    "\n",
    "            for j in range(numItems):\n",
    "                if utilityMatrix[i][j] != 0:\n",
    "                    utilityMatrix[i][j] -= centreVal\n",
    "\n",
    "    unitizedUtilityMatrix = np.zeros(shape = (numUsers,numItems), dtype=np.longdouble)\n",
    "    for i in range(numUsers):\n",
    "        length = 0.0\n",
    "        for j in range(numItems):\n",
    "            length += utilityMatrix[i][j] * utilityMatrix[i][j]\n",
    "        \n",
    "        length = math.sqrt(length)\n",
    "        for j in range(numItems):\n",
    "            if(length != 0):\n",
    "                unitizedUtilityMatrix[i][j] = utilityMatrix[i][j] / length\n",
    "            else:\n",
    "                unitizedUtilityMatrix[i][j] = 0\n",
    "                #print(\"Possible loss of accuracy. Numerator is :  \" + str(unitizedUtilityMatrix[i][j]))\n",
    "    \n",
    "    ''' \n",
    "        Numpy Matrix multiplication was much faster than the normal usage. This has been \n",
    "        experimentally verified\n",
    "    '''\n",
    "    similarityMatrix = np.dot(unitizedUtilityMatrix, np.transpose(unitizedUtilityMatrix))\n",
    "    return similarityMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns indices, sorted from the ones with the highest similarity to the lowest. Doesnt remove itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This function looks at the the similarity scores and return the indexes in a descending order by similarity'''\n",
    "def sortedBySimilarity(similarityArray):\n",
    "    assert type(similarityArray) == np.ndarray and len(similarityArray.shape) == 1 \n",
    "    similarityArray = np.copy(similarityArray)\n",
    "    almostRet = []\n",
    "    for i in range(len(similarityArray)):\n",
    "        almostRet.append((i,similarityArray[i]))\n",
    "    \n",
    "    almostRet = sorted(almostRet,key=lambda x : x[1],reverse=True)\n",
    "    ret = []\n",
    "    for i in almostRet:\n",
    "        ret.append(i[0])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Global Baseline Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBaselineParameters(utilityMatrix):\n",
    "    userAverages  = []\n",
    "    movieAverages = []\n",
    "    globalSumRatings = 0\n",
    "    globalNumRatedMovies = 0\n",
    "    for userRatings in utilityMatrix:\n",
    "        numRatedMovies = 0\n",
    "        sumRatings = 0\n",
    "        \n",
    "        for j in userRatings:\n",
    "            if j != 0:\n",
    "                numRatedMovies += 1\n",
    "                sumRatings += j\n",
    "                globalNumRatedMovies += 1\n",
    "                globalSumRatings += j\n",
    "     \n",
    "        userAverages.append(sumRatings/numRatedMovies)\n",
    "        \n",
    "    for movieRatings in utilityMatrix.T:\n",
    "        numRatedMovies = 0\n",
    "        sumRatings = 0\n",
    "        \n",
    "        for j in movieRatings:\n",
    "            if j != 0:\n",
    "                numRatedMovies += 1\n",
    "                sumRatings += j\n",
    "        movieAverages.append(sumRatings / numRatedMovies)\n",
    "    \n",
    "    globalAverage = globalSumRatings / globalNumRatedMovies\n",
    "    \n",
    "    userDeviations = userAverages - globalAverage\n",
    "    movieDeviations = movieAverages - globalAverage\n",
    "\n",
    "    return (globalAverage, userDeviations, movieDeviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System using Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User User Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def userUserCF(utilityMatrix, similarityMatrix,userItemPredictList, k = 1):\n",
    "    userToPredictWith = dict()\n",
    "    for pair in userItemPredictList:\n",
    "        user = pair[0]\n",
    "        item = pair[1]\n",
    "        if user not in userToPredictWith:\n",
    "            userToPredictWith[user] = [item]\n",
    "        else:\n",
    "            userToPredictWith[user].append(item)\n",
    "    \n",
    "    returnList = []\n",
    "    \n",
    "    for user in userToPredictWith:\n",
    "        similarityIndex = sortedBySimilarity(similarityMatrix[user])\n",
    "        similarityIndex.remove(user)\n",
    "        for item in userToPredictWith[user]:\n",
    "            similarityRatingList = []\n",
    "            rating = 0.0\n",
    "            sumSimilarities = 0.0\n",
    "            for similarUser in similarityIndex:\n",
    "                if utilityMatrix[similarUser][item] != 0: \n",
    "                        similarityRatingList.append( (similarityMatrix[user][similarUser],\\\n",
    "                                                     utilityMatrix[similarUser][item]) )\n",
    "                if len(similarityRatingList) >= k:\n",
    "                    break\n",
    "            for p in similarityRatingList:\n",
    "                rating += p[0]*p[1]\n",
    "                sumSimilarities += p[0]\n",
    "            if sumSimilarities != 0:\n",
    "                rating = rating / sumSimilarities\n",
    "            else:\n",
    "                rating = 0\n",
    "            returnList.append( (user,item,rating) )\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item Item Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemItemCF(utilityMatrix, similarityMatrix, userItemPredictList, k=1):\n",
    "    itemsToPredictWith = dict()\n",
    "    for pair in userItemPredictList:\n",
    "        user = pair[0]\n",
    "        item = pair[1]\n",
    "        if item not in itemsToPredictWith:\n",
    "            itemsToPredictWith[item] = [user]\n",
    "        else:\n",
    "            itemsToPredictWith[item].append(user)\n",
    "    \n",
    "    returnList = []\n",
    "    \n",
    "    for item in itemsToPredictWith:\n",
    "        similarityIndex = sortedBySimilarity(similarityMatrix[item])\n",
    "        \n",
    "        for user in itemsToPredictWith[item]:\n",
    "            similarityRatingList = []\n",
    "            rating = 0.0\n",
    "            sumSimilarities = 0.0\n",
    "            for similarItem in similarityIndex:\n",
    "                if utilityMatrix[user][similarItem] != 0:\n",
    "                    similarityRatingList.append( (similarityMatrix[item][similarItem],\\\n",
    "                                                 utilityMatrix[user][similarItem]) )\n",
    "                if len(similarityRatingList) >= k:\n",
    "                    break\n",
    "            for p in similarityRatingList:\n",
    "                rating += p[0]*p[1]\n",
    "                sumSimilarities += p[0]\n",
    "            if sumSimilarities != 0:\n",
    "                rating = rating / sumSimilarities\n",
    "            else:\n",
    "                rating = 0\n",
    "            returnList.append( (user,item,rating) )\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering with Global Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineCF(utilityMatrix, similarityMatrix, userItemPredictList, k=1):\n",
    "    globalAverage, userDeviations, movieDeviations = getBaselineParameters(utilityMatrix)\n",
    "    matrixShape = utilityMatrix.shape\n",
    "    base = np.zeros(shape=matrixShape)\n",
    "    baselineUtilityMatrix = base + movieDeviations\n",
    "    baselineUtilityMatrix = baselineUtilityMatrix.T\n",
    "    baselineUtilityMatrix = baselineUtilityMatrix + userDeviations\n",
    "    baselineUtilityMatrix = baselineUtilityMatrix.T\n",
    "    \n",
    "    alternateUtility = utilityMatrix - baselineUtilityMatrix\n",
    "    \n",
    "    ret = itemItemCF(alternateUtility, similarityMatrix, userItemPredictList,k)\n",
    "    retNew = []\n",
    "    for r in ret:\n",
    "        retNew.append( (r[0], r[1], r[2] + baselineUtilityMatrix[r[0]][r[1]]) )\n",
    "    \n",
    "    return retNew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy(sigma, reqd_energy):\n",
    "    \"\"\"\n",
    "    Calculates the number of singular values to retain in order to ensure the specified energy is retained.\n",
    "    :param sigma: singular values array\n",
    "    :param reqd_energy: energy to retain\n",
    "    :return: num_singular_vals\n",
    "    \"\"\"\n",
    "    if sigma.ndim == 2:\n",
    "        sigma = np.squeeze(sigma)\n",
    "    if reqd_energy == 0:\n",
    "        return -1\n",
    "    # calculate total sum\n",
    "    total_energy = np.sum(sigma)\n",
    "\n",
    "    # calculate percent energy\n",
    "    percentage_reqd_energy = reqd_energy * total_energy / 100.0\n",
    "\n",
    "    # calculate cumulative sum of the singular values in non-decreasing order\n",
    "    indexSum = sigma.cumsum()\n",
    "    checkSum = indexSum <= percentage_reqd_energy\n",
    "\n",
    "    # number of singular values to consider\n",
    "    last_singular_val_pos = np.argmin(checkSum)\n",
    "    num_singular_vals = last_singular_val_pos + 1\n",
    "    return num_singular_vals\n",
    "\n",
    "def compute_svd(A, energy_retain=90):\n",
    "    \"\"\"\n",
    "    :param A: matrix to be decomposed\n",
    "    :param energy_retain: energy to retain\n",
    "    :return: U, sigma, Vtr\n",
    "    \"\"\"\n",
    "    # get eigen values and vectors\n",
    "    eig_vals, eig_vecs = LA.eig( np.dot(A.T, A))\n",
    "    eig_vals = np.absolute(np.real(eig_vals))\n",
    "    #print('eigen values: {}\\n\\neigen vectors: {}'.format(eig_vals, eig_vecs))\n",
    "    \n",
    "    # calculate the number of eigen values to retain\n",
    "    if energy_retain == 100:\n",
    "        eig_vals_num = LA.matrix_rank(np.dot(A.T, A))\n",
    "    else:\n",
    "        # sort eigen values in increasing order and compute the number of eigen values to be retained\n",
    "        eig_vals_num = energy(np.sort(eig_vals)[::-1], energy_retain)\n",
    "\n",
    "    ##print('No of eigenvalues retained:{}'.format(eig_vals_num))\n",
    "    # place the eigen vectors according to increasing order of their corresponding eigen values to form V\n",
    "    eig_vecs_num = np.argsort(eig_vals)[::-1][0:eig_vals_num]  # TODO\n",
    "    V = np.real(eig_vecs[:, eig_vecs_num])\n",
    "    \n",
    "    # Calculation of sigma | sort in decreasing order and fill till number of eigen values to retain\n",
    "    sigma_vals = np.reshape(np.sqrt(np.sort(eig_vals)[::-1])[0:eig_vals_num], eig_vals_num)\n",
    "    sigma = np.zeros([eig_vals_num, eig_vals_num])\n",
    "    np.fill_diagonal(sigma, sigma_vals)\n",
    "\n",
    "    # Calculation of U by using U = AVS^-1\n",
    "    U = np.dot(A, np.dot(V, LA.inv(sigma)))\n",
    "\n",
    "    Vtr = V.T\n",
    "    #print(\"U: {}\".format(U))\n",
    "    #print(\"sigma: {}\".format(sigma))\n",
    "    #print(\"V_transpose: {}\".format(Vtr))\n",
    "    return U, sigma, Vtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def row_col_selection(A, r, repeat):\n",
    "    \"\"\"\n",
    "    Function for row/column selection from A to form R/C respectively\n",
    "    :param A: matrix to be decomposed\n",
    "    :param r: number of selections\n",
    "    :param repeat: is repetitive selection allowed or not\n",
    "    :return: selected rows, R\n",
    "    \"\"\"\n",
    "    index_set = [i for i in range(len(A))]\n",
    "    frob = 0\n",
    "\n",
    "    # compute frobenius norm for A\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(A[i])):\n",
    "            frob += A[i][j] ** 2\n",
    "\n",
    "    # compute prob for random selection of rows and columns\n",
    "    prob = np.zeros(len(A))\n",
    "    for i in range(len(A)):\n",
    "        sum_sqr_row_vals = 0\n",
    "        for j in range(len(A[i])):\n",
    "            sum_sqr_row_vals += A[i][j]**2\n",
    "        prob[i] = sum_sqr_row_vals / float(frob)\n",
    "\n",
    "    sel_rows = np.random.choice(index_set, r, repeat, prob)\n",
    "\n",
    "    # form R/C with random selected rows/columns\n",
    "    R = np.zeros((r, len(A[0])))\n",
    "    for i, row in zip(range(r), sel_rows):\n",
    "        for j in range(len(A[row])):\n",
    "            R[i][j] = A[row][j]\n",
    "            R[i][j] = R[i][j]/float(math.sqrt(r*prob[row]))\n",
    "\n",
    "    return sel_rows, R\n",
    "\n",
    "\n",
    "def compute_U(A, r, row_idx, col_idx, ret_energy):\n",
    "    \"\"\"\n",
    "    Computation of U using Moore-Pennrose pseudoinverse\n",
    "    :param A: matrix to be decomposed\n",
    "    :param r: number of row/col selection\n",
    "    :param row_idx: set of selected row indices\n",
    "    :param col_idx: set of selected column indices\n",
    "    :return: U\n",
    "    \"\"\"\n",
    "    # Form W by intersection of C and R\n",
    "    W = np.zeros((r, r))\n",
    "    for i, row in zip(range(len(row_idx)), row_idx):\n",
    "        for j, column in zip(range(len(col_idx)), col_idx):\n",
    "            W[i][j] = A[row][column]\n",
    "\n",
    "    # Compute pseudo-inverse of W\n",
    "    X, sigma, Ytr = compute_svd(W, ret_energy)\n",
    "    sig_plus = np.zeros((sigma.shape[0], sigma.shape[1]))\n",
    "\n",
    "    # replace non-zero sigma values with its inverse\n",
    "    for i in range(len(sigma)):\n",
    "        if sigma[i][i] != 0:\n",
    "            sig_plus[i][i] = 1/float(sigma[i][i])\n",
    "\n",
    "    # finally compute U with the given formula\n",
    "    U = np.dot(np.dot(Ytr.T, np.dot(sig_plus, sig_plus)), X.T)\n",
    "\n",
    "    return U\n",
    "\n",
    "\n",
    "def compute_cur(A, r, ret_energy):\n",
    "    \"\"\"\n",
    "    Main function to comput C, U, R\n",
    "    :param A: matrix to be decomposed\n",
    "    :param r: number of row/col selection\n",
    "    :return: C, U, R\n",
    "    \"\"\"\n",
    "    row_idx, tmpR = row_col_selection(A, r, False)\n",
    "    col_idx, tmpC = row_col_selection(A.T, r, False)\n",
    "    R = tmpR\n",
    "    C = tmpC.T\n",
    "\n",
    "    # print(R)\n",
    "    U = compute_U(A, r, row_idx, col_idx, ret_energy)\n",
    "    #print(np.dot(np.dot(C, U), R))\n",
    "\n",
    "    return C, U, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsme(utilityMatrix, predictedValuesTupleList):\n",
    "    n = len(predictedValuesTupleList)\n",
    "    sumSquaredDistances = 0.00\n",
    "    for tup in predictedValuesTupleList:\n",
    "        user = tup[0]\n",
    "        item = tup[1]\n",
    "        rating = tup[2]\n",
    "        diff = utilityMatrix[user][item] - rating\n",
    "        sumSquaredDistances += diff*diff\n",
    "    sumSquaredDistances = sumSquaredDistances / n\n",
    "    return math.sqrt(sumSquaredDistances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spearman(utilityMatrix, predictedValuesTupleList):\n",
    "    n = len(predictedValuesTupleList)\n",
    "    sumSquaredDistances = 0.00\n",
    "    for tup in predictedValuesTupleList:\n",
    "        user = tup[0]\n",
    "        item = tup[1]\n",
    "        rating = tup[2]\n",
    "        diff = utilityMatrix[user][item] - rating\n",
    "        sumSquaredDistances += diff*diff\n",
    "    spearmanCoeff = 1.0 - 6.0*sumSquaredDistances/(n*(n-1)*(n+1))\n",
    "    return spearmanCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precisionAtK(utilityMatrix, predictedValuesTupleList, k = 35000, recommedCutOff = 2.5):\n",
    "    #almostRet = sorted(almostRet,key=lambda x : x[1],reverse=True)\n",
    "    predictedValuesTupleList = sorted(predictedValuesTupleList, key=lambda x : x[2], reverse = True)\n",
    "    systemRecommends = 0\n",
    "    realRecommends = 0\n",
    "    for i in range(k):\n",
    "        userId = predictedValuesTupleList[i][0]\n",
    "        itemId = predictedValuesTupleList[i][1]\n",
    "        testRec = predictedValuesTupleList[i][2] > recommedCutOff\n",
    "        realRec = utilityMatrix[userId][itemId] > recommedCutOff\n",
    "        if testRec:\n",
    "            systemRecommends += 1\n",
    "    return systemRecommends / k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all recommender systems with statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testRatingMatrix is the test utility matrix \n",
    "### testPairList is the \n",
    "### ratingsMatrix is the actual utility matrix\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (User User) Collaborative Filtering (without handling strict and generous raters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 5.966830218\n",
      "RSME     = 1.0872568586175646\n",
      "Spearman = 0.9999999955877837428\n",
      "Prec@K   : 1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "uusim = generateSimilarityMatrix(testRatingMatrix, 'user-user', center= False)\n",
    "predicts = userUserCF(testRatingMatrix,uusim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (User User) Collaborative Filtering (handling strict and generous raters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 7.495272851999999\n",
      "RSME     = 1.1505162127509043\n",
      "Spearman = 0.99999999505941967456\n",
      "Prec@K   : 0.9859142857142857\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "uusim = generateSimilarityMatrix(testRatingMatrix, 'user-user')\n",
    "predicts = userUserCF(testRatingMatrix,uusim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Item Item) Collaborative Filtering (without handling generous and strict raters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 8.589506576999998\n",
      "RSME     = 0.5353389052320383\n",
      "Spearman = 0.9999999989303293208\n",
      "Prec@K   : 1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "iisim = generateSimilarityMatrix(testRatingMatrix, 'item-item', center= False)\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Item Item) Collaborative Filtering (handling generous and strict raters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 10.281696169\n",
      "RSME     = 0.30995527697619024\n",
      "Spearman = 0.999999999641416297\n",
      "Prec@K   : 0.9593714285714285\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "iisim = generateSimilarityMatrix(testRatingMatrix, 'item-item')\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Item Item) Collaborative Filtering with Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 10.893180438000002\n",
      "RSME     = 0.9714891356713724\n",
      "Spearman = 0.99999999647735908617\n",
      "Prec@K   : 0.6992857142857143\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "iisim = generateSimilarityMatrix(testRatingMatrix, 'item-item')\n",
    "predicts = baselineCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using SVD to generate Item Item similarity (with 100% energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time for SVD: 13.903737756000005\n",
      "CPU Time : 24.193614435000008\n",
      "RSME     = 0.11631906097256046\n",
      "Spearman = 0.9999999999494996656\n",
      "Prec@K   : 0.9452285714285714\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "_,__,vtr = compute_svd(testRatingMatrix, energy_retain =100)\n",
    "inbetween = time.process_time()\n",
    "print(\"CPU Time for SVD: \" + str(inbetween - start))\n",
    "iisim = generateSimilarityMatrix(vtr,'item-item',center=False)\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using SVD to generate Item Item similarity (with 90% energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time for SVD: 6.318248280000006\n",
      "CPU Time : 11.88517726100001\n",
      "RSME     = 0.28683458021289965\n",
      "Spearman = 0.9999999996929171983\n",
      "Prec@K   : 0.9583142857142857\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "_,__,vtr = compute_svd(testRatingMatrix, energy_retain =90)\n",
    "inbetween = time.process_time()\n",
    "print(\"CPU Time for SVD: \" + str(inbetween - start))\n",
    "iisim = generateSimilarityMatrix(vtr,'item-item',center=True)\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using CUR to generate Item Item similarity (with 100% energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 12.032446805000006\n",
      "RSME     = 0.4793803153369837\n",
      "Spearman = 0.99999999914226551316\n",
      "Prec@K   : 0.9955714285714286\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "C, U, R = compute_cur(testRatingMatrix, r=470, ret_energy=100)\n",
    "iisim = generateSimilarityMatrix(R,'item-item',center=True)\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation using CUR to generate Item Item similarity (with 90% energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time : 12.269587239000003\n",
      "RSME     = 0.4854692045928863\n",
      "Spearman = 0.9999999991203379617\n",
      "Prec@K   : 0.9942\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "C, U, R = compute_cur(testRatingMatrix, r=470, ret_energy=90)\n",
    "iisim = generateSimilarityMatrix(R,'item-item',center=True)\n",
    "predicts = itemItemCF(testRatingMatrix,iisim,testPairList,k)\n",
    "end = time.process_time()\n",
    "print(\"CPU Time : \" + str(end-start))\n",
    "rsmeVal = rsme(ratingsMatrix, predicts)\n",
    "print(\"RSME     = \" + str(rsmeVal))\n",
    "spearmanVal = spearman(ratingsMatrix,predicts)\n",
    "print(\"Spearman = \" + str(spearmanVal))\n",
    "patk = precisionAtK(ratingsMatrix, predicts)\n",
    "print(\"Prec@K   : \" + str(patk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
